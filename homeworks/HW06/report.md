# HW06 – Report## 1. Dataset- Какой датасет выбран: `S06-hw-dataset-02.csv`- Размер: 18000 строк, 37 признаков- Целевая переменная: `target`  - класс 0: 13273 (73.74%)  - класс 1: 4727 (26.26%)- Признаки: все числовые (при необходимости некоторые были приведены к числовому типу).## 2. Protocol- Разбиение: train/test = 0.75/0.25, random_state=42- Подбор: GridSearchCV на train, cv folds: 4-5 (см. код), оптимизировали `roc_auc` для бинарных и `f1_macro` для мультикласса.- Метрики: accuracy, F1, ROC-AUC (выбор метрик обоснован в ноутбуке)## 3. Models- DummyClassifier (most_frequent) — baseline- LogisticRegression (Pipeline: StandardScaler + LogisticRegression), C подбирался по сетке- DecisionTreeClassifier — подбирали max_depth и min_samples_leaf- RandomForestClassifier — подбирали max_depth, max_features, min_samples_leaf- GradientBoostingClassifier — подбирали learning_rate и max_depth- (Опционально) StackingClassifier из RF+GB+DT с логистическим мета-классификатором## 4. ResultsТаблица финальных метрик на test:| model              |   accuracy |   roc_auc |         f1 |
|:-------------------|-----------:|----------:|-----------:|
| Dummy              |   0.737333 |  0.5      | nan        |
| LogisticRegression |   0.816222 |  0.80089  |   0.571724 |
| DecisionTree       |   0.826    |  0.82983  |   0.62446  |
| RandomForest       |   0.889333 |  0.926607 |   0.751992 |
| GradientBoosting   |   0.895778 |  0.922108 |   0.77846  |
| Stacking           |   0.906444 |  0.927999 |   0.810104 |- Победитель: **Stacking** (по метрике `roc_auc`) — см. `artifacts/` для подробностей.## 5. Analysis- Устойчивость: для оценки устойчивости можно повторить обучение с несколькими random_state (рекомендуется 5 прогонов) и усреднить метрики.- Ошибки: confusion matrix для лучшей модели сохранена в artifacts/figures/confusion_matrix_best.png- Интерпретация: permutation importance сохранён в artifacts/feature_importance.csv и artifacts/figures/permutation_importance.png## 6. Conclusion- Ансамбли (RF/GB/Stacking) показали более высокую стабильность и качество по сравнению с одиночными деревьями и линейной моделью.- Контроль сложности дерева и подбор гиперпараметров через CV критичны для предотвращения overfitting.- Permutation importance показывает, какие признаки наиболее информативны для модели — эти результаты полезны для дальнейшего feature engineering.- Для дисбалансных задач полезно смотреть PR-кривую и average precision, а не только accuracy.- Рекомендуем сохранять лучшие модели и метаданные (как сделано в `artifacts/`) для воспроизводимости.