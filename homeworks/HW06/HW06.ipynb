{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a60b76",
   "metadata": {},
   "source": [
    "## 0. Настройки и зависимости\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8498b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "HW_DIR = Path('.')\n",
    "ARTIFACTS_DIR = HW_DIR / 'artifacts'\n",
    "FIG_DIR = ARTIFACTS_DIR / 'figures'\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b52d7",
   "metadata": {},
   "source": [
    "## 1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afd0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (18000, 39)\n",
      "\n",
      "Head:\n",
      " id       f01       f02       f03        f04       f05       f06       f07       f08       f09       f10       f11       f12       f13        f14       f15       f16       f17       f18        f19       f20       f21       f22       f23       f24      f25      f26      f27       f28       f29      f30       f31       f32       f33       f34        f35   x_int_1   x_int_2  target\n",
      "  1 -0.149235 -2.826966 -0.522901  -4.198449  1.364943  0.815043 -1.195518 -1.932232  2.396353  1.121683 -0.332250  0.303750  2.439315   3.905690 -0.679945 -1.847890 -1.450850 -0.523963  -2.203766  1.717017 -0.467238 -5.418752  5.115531  0.951900 0.085200 0.304588 0.206599  0.293322 -0.159323 0.448015  0.572745  0.149916  0.878392 -0.679733   1.412751  0.421883  9.217167       1\n",
      "  2 -1.966180 -4.877542  0.268367  -9.607791  0.097149  1.347185 -3.872575 -0.395117  1.710068 -0.298809  0.555178  3.632876  1.551984   2.671995 -4.859814 -3.454798 -0.238638  0.604069  -3.080758  0.489968 -0.536891 -5.967924  0.494241 -0.163892 0.185315 0.391446 1.906470  1.924549 -0.389212 1.383794  0.169876  0.043969 -0.963545  1.006643  -2.488690  9.590124 24.772826       0\n",
      "  3 -0.555964 -0.999920  0.209673 -14.119498 -1.808950 -0.006222 -4.651108  0.911944 -0.289037 -0.092692  6.528588  5.069781 -0.357675  -0.637326 -7.343904  1.084497  1.729089  3.436086 -14.699661  1.115379 -1.902015 -2.945627  0.334764  0.464342 0.922432 0.291900 0.871523  0.792870 -1.383970 3.044321 -0.182864  1.425649 -8.418598 -4.629754  -0.439798  0.555919 41.800517       0\n",
      "  4 -2.049199 -5.600713 -1.664677  -6.263893 -5.224455  0.848351  1.407210 -0.542080  0.119102  0.681733 -6.759153  7.319979  2.850692   0.075889  0.007788  1.023049 -0.328986  0.929586  -6.925342 -0.010655  0.626436 -2.290922 -5.093754  0.600184 0.617500 0.213250 2.849320 -0.732601 -2.713080 2.762637 -0.520796 -0.142455  1.668338  2.292810 -10.744916 11.476977 65.315860       0\n",
      "  5 -0.220556  4.889479 -2.235840   6.450046  0.774389 -2.382625  2.584816  4.211856 -0.317889 -1.275888 -6.865158 -1.636507  1.798513 -10.927353  6.128509  3.304736 -0.889584  1.401849  -5.221212 -0.925408 -1.512424  7.052793 -4.277646 -0.560136 1.152667 1.871836 0.610097  1.948262 -1.302872 2.478862  1.528610  1.098131  3.547087  2.517757  -9.364106 -1.078404 93.017870       0\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 39 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       18000 non-null  int64  \n",
      " 1   f01      18000 non-null  float64\n",
      " 2   f02      18000 non-null  float64\n",
      " 3   f03      18000 non-null  float64\n",
      " 4   f04      18000 non-null  float64\n",
      " 5   f05      18000 non-null  float64\n",
      " 6   f06      18000 non-null  float64\n",
      " 7   f07      18000 non-null  float64\n",
      " 8   f08      18000 non-null  float64\n",
      " 9   f09      18000 non-null  float64\n",
      " 10  f10      18000 non-null  float64\n",
      " 11  f11      18000 non-null  float64\n",
      " 12  f12      18000 non-null  float64\n",
      " 13  f13      18000 non-null  float64\n",
      " 14  f14      18000 non-null  float64\n",
      " 15  f15      18000 non-null  float64\n",
      " 16  f16      18000 non-null  float64\n",
      " 17  f17      18000 non-null  float64\n",
      " 18  f18      18000 non-null  float64\n",
      " 19  f19      18000 non-null  float64\n",
      " 20  f20      18000 non-null  float64\n",
      " 21  f21      18000 non-null  float64\n",
      " 22  f22      18000 non-null  float64\n",
      " 23  f23      18000 non-null  float64\n",
      " 24  f24      18000 non-null  float64\n",
      " 25  f25      18000 non-null  float64\n",
      " 26  f26      18000 non-null  float64\n",
      " 27  f27      18000 non-null  float64\n",
      " 28  f28      18000 non-null  float64\n",
      " 29  f29      18000 non-null  float64\n",
      " 30  f30      18000 non-null  float64\n",
      " 31  f31      18000 non-null  float64\n",
      " 32  f32      18000 non-null  float64\n",
      " 33  f33      18000 non-null  float64\n",
      " 34  f34      18000 non-null  float64\n",
      " 35  f35      18000 non-null  float64\n",
      " 36  x_int_1  18000 non-null  float64\n",
      " 37  x_int_2  18000 non-null  float64\n",
      " 38  target   18000 non-null  int64  \n",
      "dtypes: float64(37), int64(2)\n",
      "memory usage: 5.4 MB\n",
      "None\n",
      "\n",
      "Describe:\n",
      "           count         mean          std           min          25%  \\\n",
      "id       18000.0  9000.500000  5196.296758  1.000000e+00  4500.750000   \n",
      "f01      18000.0    -0.418555     2.178005 -1.001470e+01    -1.866134   \n",
      "f02      18000.0     0.614251     3.926778 -1.551032e+01    -2.048192   \n",
      "f03      18000.0     0.004559     1.000134 -4.031762e+00    -0.673127   \n",
      "f04      18000.0     0.059000     5.713672 -2.366326e+01    -3.544964   \n",
      "f05      18000.0     0.405086     2.497581 -1.228931e+01    -1.153000   \n",
      "f06      18000.0     0.012123     0.987226 -3.741536e+00    -0.653090   \n",
      "f07      18000.0    -0.283473     2.193891 -9.591425e+00    -1.743214   \n",
      "f08      18000.0    -0.266880     2.081431 -8.293319e+00    -1.688121   \n",
      "f09      18000.0     0.255107     2.225776 -1.365574e+01    -1.177480   \n",
      "f10      18000.0    -0.005191     1.001474 -3.907906e+00    -0.673268   \n",
      "f11      18000.0     0.631157     4.703578 -1.884241e+01    -2.496779   \n",
      "f12      18000.0     0.327920     4.759290 -2.088322e+01    -2.575461   \n",
      "f13      18000.0    -0.134225     2.226446 -9.117117e+00    -1.589181   \n",
      "f14      18000.0    -0.369264     4.468676 -1.649660e+01    -3.485540   \n",
      "f15      18000.0     0.267345     2.116606 -8.094991e+00    -1.122707   \n",
      "f16      18000.0     0.405346     1.985802 -8.213460e+00    -0.882179   \n",
      "f17      18000.0     0.002839     0.992655 -4.368946e+00    -0.659813   \n",
      "f18      18000.0     0.130219     2.237071 -8.818339e+00    -1.365920   \n",
      "f19      18000.0    -0.994571     5.683295 -2.305737e+01    -4.700504   \n",
      "f20      18000.0    -0.010144     1.000648 -4.187920e+00    -0.680167   \n",
      "f21      18000.0    -0.009039     0.995690 -3.529766e+00    -0.687256   \n",
      "f22      18000.0     0.021684     3.999158 -1.909955e+01    -2.473055   \n",
      "f23      18000.0     0.197973     4.088351 -1.608865e+01    -2.423333   \n",
      "f24      18000.0    -0.005616     1.003939 -3.884916e+00    -0.679166   \n",
      "f25      18000.0     0.007092     1.006282 -4.107881e+00    -0.662634   \n",
      "f26      18000.0    -0.009755     0.986181 -3.877028e+00    -0.670062   \n",
      "f27      18000.0    -0.009338     1.002310 -3.854263e+00    -0.681364   \n",
      "f28      18000.0    -0.000533     0.993892 -3.925510e+00    -0.669819   \n",
      "f29      18000.0    -0.139825     2.148834 -8.171469e+00    -1.589638   \n",
      "f30      18000.0     0.108568     2.234315 -9.214171e+00    -1.369266   \n",
      "f31      18000.0     0.007238     0.997861 -3.937091e+00    -0.663023   \n",
      "f32      18000.0     0.000904     1.002115 -3.963063e+00    -0.684164   \n",
      "f33      18000.0    -0.716862     3.913704 -1.938991e+01    -3.286842   \n",
      "f34      18000.0    -0.274520     2.482890 -1.003156e+01    -1.897893   \n",
      "f35      18000.0     0.344991     4.927315 -2.076845e+01    -2.752685   \n",
      "x_int_1  18000.0     1.517339    10.630850 -1.077881e+02    -2.018750   \n",
      "x_int_2  18000.0    25.762213    54.237475  1.895059e-07     1.226029   \n",
      "target   18000.0     0.262611     0.440065  0.000000e+00     0.000000   \n",
      "\n",
      "                 50%           75%           max  \n",
      "id       9000.500000  13500.250000  18000.000000  \n",
      "f01        -0.465100      0.966393      9.589975  \n",
      "f02         0.600291      3.229850     15.417329  \n",
      "f03         0.003581      0.671390      3.817025  \n",
      "f04         0.072826      3.689490     26.815691  \n",
      "f05         0.485625      2.075739     10.665184  \n",
      "f06         0.018765      0.689304      3.528280  \n",
      "f07        -0.251263      1.195481      7.794627  \n",
      "f08        -0.302463      1.109589      8.892834  \n",
      "f09         0.350739      1.764113      8.699629  \n",
      "f10        -0.002402      0.679554      3.829719  \n",
      "f11         0.685619      3.769763     19.252329  \n",
      "f12         0.395990      3.363087     19.877364  \n",
      "f13        -0.059719      1.394537      8.101997  \n",
      "f14        -0.597937      2.563241     17.088092  \n",
      "f15         0.294776      1.694409      9.312819  \n",
      "f16         0.418423      1.733266      8.077667  \n",
      "f17         0.002829      0.686807      3.362864  \n",
      "f18         0.123403      1.625329      8.720620  \n",
      "f19        -0.869548      2.767109     23.292978  \n",
      "f20        -0.011155      0.669025      3.922051  \n",
      "f21        -0.015796      0.661419      3.861147  \n",
      "f22         0.045413      2.632254     17.342356  \n",
      "f23         0.165875      2.842752     19.707688  \n",
      "f24        -0.008946      0.667357      4.722701  \n",
      "f25         0.008993      0.684551      4.032127  \n",
      "f26        -0.005141      0.652257      4.239447  \n",
      "f27        -0.009696      0.662224      3.773627  \n",
      "f28         0.003124      0.673979      4.706989  \n",
      "f29        -0.204785      1.254595      9.290667  \n",
      "f30         0.158715      1.600671      8.794320  \n",
      "f31         0.001912      0.677296      4.341030  \n",
      "f32        -0.003157      0.676558      3.781380  \n",
      "f33        -0.618472      1.948803     14.065595  \n",
      "f34        -0.339901      1.314163     10.639974  \n",
      "f35         0.573153      3.649794     20.226291  \n",
      "x_int_1     0.318011      4.212111     94.891804  \n",
      "x_int_2     6.581865     25.768474   1103.449067  \n",
      "target      0.000000      1.000000      1.000000  \n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "0    13273\n",
      "1     4727\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    0.737389\n",
      "1    0.262611\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"S06-hw-dataset-02.csv\")\n",
    "print('Shape:', df.shape)\n",
    "print('\\nHead:')\n",
    "print(df.head().to_string(index=False))\n",
    "\n",
    "print('\\nInfo:')\n",
    "print(df.info())\n",
    "\n",
    "print('\\nDescribe:')\n",
    "print(df.describe().T)\n",
    "\n",
    "if 'target' not in df.columns:\n",
    "    raise ValueError('CSV не содержит столбца target')\n",
    "\n",
    "print('\\nTarget distribution:')\n",
    "print(df['target'].value_counts(dropna=False))\n",
    "print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472cbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Подготовка X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e4df64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric cols: []\n",
      "\n",
      "Missing summary:\n",
      "f01    0\n",
      "f02    0\n",
      "f03    0\n",
      "f04    0\n",
      "f05    0\n",
      "f06    0\n",
      "f07    0\n",
      "f08    0\n",
      "f09    0\n",
      "f10    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Убираем id-колонку\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "X = df.drop(columns=['target']).copy()\n",
    "y = df['target'].copy()\n",
    "\n",
    "# Приводим нечисловые признаки к числовым, если можно\n",
    "non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print('Non-numeric cols:', non_numeric)\n",
    "if non_numeric:\n",
    "    for c in non_numeric:\n",
    "        try:\n",
    "            X[c] = pd.to_numeric(X[c])\n",
    "        except Exception:\n",
    "            print(f\"Column {c} is non-numeric and cannot be directly converted; consider encoding.\")\n",
    "\n",
    "# Проверка пропусков\n",
    "print('\\nMissing summary:')\n",
    "print(X.isna().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50fdd8",
   "metadata": {},
   "source": [
    "## 4. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd1818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (13500, 37) Test shape: (4500, 37)\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d96f29",
   "metadata": {},
   "source": [
    "## 5. Baselines: Dummy + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b6598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy metrics: {'accuracy': 0.7373333333333333, 'roc_auc': 0.5}\n",
      "LR best params: {'lr__C': 1.0} best score: 0.803353171075198\n",
      "LogReg metrics: {'accuracy': 0.8162222222222222, 'roc_auc': 0.8008904412072182, 'f1': 0.5717244950802693}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "search_summaries = {}\n",
    "\n",
    "# Dummy baseline\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "try:\n",
    "    y_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_dummy = None\n",
    "\n",
    "metrics_dummy = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_dummy)),\n",
    "}\n",
    "if y_proba_dummy is not None and len(np.unique(y_test)) == 2:\n",
    "    metrics_dummy['roc_auc'] = float(roc_auc_score(y_test, y_proba_dummy))\n",
    "else:\n",
    "    metrics_dummy['roc_auc'] = None\n",
    "\n",
    "results['Dummy'] = metrics_dummy\n",
    "print('Dummy metrics:', metrics_dummy)\n",
    "\n",
    "# LogisticRegression baseline\n",
    "pipe_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "])\n",
    "param_grid_lr = {'lr__C': [0.01, 0.1, 1.0, 10.0]}\n",
    "scoring = 'roc_auc' if len(np.unique(y)) == 2 else 'f1_macro'\n",
    "\n",
    "gs_lr = GridSearchCV(pipe_lr, param_grid_lr, scoring=scoring, cv=5, n_jobs=-1)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "\n",
    "print('LR best params:', gs_lr.best_params_, 'best score:', gs_lr.best_score_)\n",
    "\n",
    "best_lr = gs_lr.best_estimator_\n",
    "y_pred_lr = best_lr.predict(X_test)\n",
    "try:\n",
    "    y_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_lr = None\n",
    "\n",
    "metrics_lr = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_lr)),\n",
    "}\n",
    "if len(np.unique(y)) == 2 and y_proba_lr is not None:\n",
    "    metrics_lr['roc_auc'] = float(roc_auc_score(y_test, y_proba_lr))\n",
    "else:\n",
    "    metrics_lr['roc_auc'] = None\n",
    "\n",
    "# f1\n",
    "metrics_lr['f1'] = float(f1_score(y_test, y_pred_lr, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "results['LogisticRegression'] = metrics_lr\n",
    "search_summaries['LogisticRegression'] = {'best_params': gs_lr.best_params_, 'cv_score': gs_lr.best_score_}\n",
    "print('LogReg metrics:', metrics_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861044f",
   "metadata": {},
   "source": [
    "## 6. Week-6 models: DecisionTree, RandomForest, GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37aaa297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT best: {'max_depth': 8, 'min_samples_leaf': 10} 0.8295161796490411\n",
      "DecisionTree metrics: {'accuracy': 0.826, 'f1': 0.6244604316546762, 'roc_auc': 0.829829780441809}\n",
      "RF best: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100} 0.9232905214065784\n",
      "RandomForest metrics: {'accuracy': 0.8893333333333333, 'f1': 0.75199203187251, 'roc_auc': 0.9266073175184528}\n",
      "GB best: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100} 0.92187810312377\n",
      "GradientBoosting metrics: {'accuracy': 0.8957777777777778, 'f1': 0.7784600850259802, 'roc_auc': 0.9221071752396046}\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 8, None],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    # 'ccp_alpha': [0.0, 0.001, 0.01]\n",
    "}\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "gs_dt = GridSearchCV(dt, param_grid_dt, scoring=scoring, cv=5, n_jobs=-1)\n",
    "gs_dt.fit(X_train, y_train)\n",
    "print('DT best:', gs_dt.best_params_, gs_dt.best_score_)\n",
    "best_dt = gs_dt.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "try:\n",
    "    y_proba_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_dt = None\n",
    "\n",
    "metrics_dt = {'accuracy': float(accuracy_score(y_test, y_pred_dt))}\n",
    "metrics_dt['f1'] = float(f1_score(y_test, y_pred_dt, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "metrics_dt['roc_auc'] = float(roc_auc_score(y_test, y_proba_dt)) if (y_proba_dt is not None and len(np.unique(y))==2) else None\n",
    "results['DecisionTree'] = metrics_dt\n",
    "search_summaries['DecisionTree'] = {'best_params': gs_dt.best_params_, 'cv_score': gs_dt.best_score_}\n",
    "print('DecisionTree metrics:', metrics_dt)\n",
    "\n",
    "# 6.2 Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5, 8, None],\n",
    "    'max_features': ['sqrt', 0.5],\n",
    "    'min_samples_leaf': [1, 5]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "gs_rf = GridSearchCV(rf, param_grid_rf, scoring=scoring, cv=4, n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "print('RF best:', gs_rf.best_params_, gs_rf.best_score_)\n",
    "best_rf = gs_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "try:\n",
    "    y_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_rf = None\n",
    "\n",
    "metrics_rf = {'accuracy': float(accuracy_score(y_test, y_pred_rf))}\n",
    "metrics_rf['f1'] = float(f1_score(y_test, y_pred_rf, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "metrics_rf['roc_auc'] = float(roc_auc_score(y_test, y_proba_rf)) if (y_proba_rf is not None and len(np.unique(y))==2) else None\n",
    "results['RandomForest'] = metrics_rf\n",
    "search_summaries['RandomForest'] = {'best_params': gs_rf.best_params_, 'cv_score': gs_rf.best_score_}\n",
    "print('RandomForest metrics:', metrics_rf)\n",
    "\n",
    "# 6.3 Gradient Boosting (sklearn)\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "gb = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "gs_gb = GridSearchCV(gb, param_grid_gb, scoring=scoring, cv=4, n_jobs=-1)\n",
    "gs_gb.fit(X_train, y_train)\n",
    "print('GB best:', gs_gb.best_params_, gs_gb.best_score_)\n",
    "best_gb = gs_gb.best_estimator_\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "try:\n",
    "    y_proba_gb = best_gb.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_gb = None\n",
    "\n",
    "metrics_gb = {'accuracy': float(accuracy_score(y_test, y_pred_gb))}\n",
    "metrics_gb['f1'] = float(f1_score(y_test, y_pred_gb, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "metrics_gb['roc_auc'] = float(roc_auc_score(y_test, y_proba_gb)) if (y_proba_gb is not None and len(np.unique(y))==2) else None\n",
    "results['GradientBoosting'] = metrics_gb\n",
    "search_summaries['GradientBoosting'] = {'best_params': gs_gb.best_params_, 'cv_score': gs_gb.best_score_}\n",
    "print('GradientBoosting metrics:', metrics_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45393387",
   "metadata": {},
   "source": [
    "## 7. Stacking — собираем несколько сильных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c959553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking metrics: {'accuracy': 0.9064444444444445, 'f1': 0.8101037437979252, 'roc_auc': 0.927999253418517}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    estimators = [\n",
    "        ('rf', best_rf),\n",
    "        ('gb', best_gb),\n",
    "        ('dt', best_dt),\n",
    "    ]\n",
    "    stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), n_jobs=-1)\n",
    "    stack.fit(X_train, y_train)\n",
    "    y_pred_stack = stack.predict(X_test)\n",
    "    try:\n",
    "        y_proba_stack = stack.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        y_proba_stack = None\n",
    "    metrics_stack = {'accuracy': float(accuracy_score(y_test, y_pred_stack))}\n",
    "    metrics_stack['f1'] = float(f1_score(y_test, y_pred_stack, average='binary' if len(np.unique(y))==2 else 'macro'))\n",
    "    metrics_stack['roc_auc'] = float(roc_auc_score(y_test, y_proba_stack)) if (y_proba_stack is not None and len(np.unique(y))==2) else None\n",
    "    results['Stacking'] = metrics_stack\n",
    "    print('Stacking metrics:', metrics_stack)\n",
    "except Exception as exc:\n",
    "    print('Stacking failed or skipped:', exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34696d8b",
   "metadata": {},
   "source": [
    "## 8. Сводная таблица результатов и выбор лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8f27d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results (test metrics):\n",
      "                    accuracy   roc_auc        f1\n",
      "model                                           \n",
      "Dummy               0.737333  0.500000       NaN\n",
      "LogisticRegression  0.816222  0.800890  0.571724\n",
      "DecisionTree        0.826000  0.829830  0.624460\n",
      "RandomForest        0.889333  0.926607  0.751992\n",
      "GradientBoosting    0.895778  0.922107  0.778460\n",
      "Stacking            0.906444  0.927999  0.810104\n",
      "\n",
      "CV scores on train (used for model selection):\n",
      "  Dummy: 0.5\n",
      "  LogisticRegression: 0.803353171075198\n",
      "  DecisionTree: 0.8295161796490411\n",
      "  RandomForest: 0.9232905214065784\n",
      "  GradientBoosting: 0.92187810312377\n",
      "  Stacking: 0.9274067577724585\n",
      "\n",
      "Selected best model by CV on train: Stacking\n",
      "Final model object used for test evaluation: StackingClassifier(cv=5,\n",
      "                   estimators=[('rf',\n",
      "                                RandomForestClassifier(n_jobs=-1,\n",
      "                                                       random_state=42)),\n",
      "                               ('gb',\n",
      "                                GradientBoostingClassifier(max_depth=5,\n",
      "                                                           random_state=42)),\n",
      "                               ('dt',\n",
      "                                DecisionTreeClassifier(max_depth=8,\n",
      "                                                       min_samples_leaf=10,\n",
      "                                                       random_state=42))],\n",
      "                   final_estimator=LogisticRegression(max_iter=2000),\n",
      "                   n_jobs=-1)\n",
      "Selected best model test metrics: {'accuracy': 0.9064444444444445, 'f1': 0.8101037437979252, 'roc_auc': 0.927999253418517}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Сформируем DataFrame результатов\n",
    "results_df = pd.DataFrame([{'model': k, **v} for k, v in results.items()]).set_index('model')\n",
    "print('\\nResults (test metrics):')\n",
    "print(results_df)\n",
    "\n",
    "# Выбираем метрику для отбора (консистентно с тем, что использовалось в CV)\n",
    "if len(np.unique(y)) == 2:\n",
    "    metric_for_selection = 'roc_auc'\n",
    "else:\n",
    "    metric_for_selection = 'f1'\n",
    "\n",
    "# Соберём CV-оценки на train для всех кандидатов\n",
    "model_cv_scores = {}\n",
    "\n",
    "# Dummy: cross_val_score на train\n",
    "try:\n",
    "    model_cv_scores['Dummy'] = float(cross_val_score(dummy, X_train, y_train, cv=5, scoring=scoring, n_jobs=-1).mean())\n",
    "except Exception:\n",
    "    model_cv_scores['Dummy'] = None\n",
    "\n",
    "# Для моделей, где мы использовали GridSearchCV\n",
    "model_cv_scores['LogisticRegression'] = float(gs_lr.best_score_) if 'gs_lr' in locals() else None\n",
    "model_cv_scores['DecisionTree'] = float(gs_dt.best_score_) if 'gs_dt' in locals() else None\n",
    "model_cv_scores['RandomForest'] = float(gs_rf.best_score_) if 'gs_rf' in locals() else None\n",
    "model_cv_scores['GradientBoosting'] = float(gs_gb.best_score_) if 'gs_gb' in locals() else None\n",
    "\n",
    "# Stacking\n",
    "if 'gs_rf' in locals() and 'gs_gb' in locals() and 'gs_dt' in locals():\n",
    "    try:\n",
    "        # Создаём новые экземляры с лучшими параметрами\n",
    "        rf_cv = RandomForestClassifier(**gs_rf.best_params_, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    except Exception:\n",
    "        rf_cv = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    try:\n",
    "        gb_cv = GradientBoostingClassifier(**gs_gb.best_params_, random_state=RANDOM_STATE)\n",
    "    except Exception:\n",
    "        gb_cv = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    try:\n",
    "        dt_cv = DecisionTreeClassifier(**gs_dt.best_params_, random_state=RANDOM_STATE)\n",
    "    except Exception:\n",
    "        dt_cv = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "    try:\n",
    "        stack_cv_cl = StackingClassifier(\n",
    "            estimators=[('rf', rf_cv), ('gb', gb_cv), ('dt', dt_cv)],\n",
    "            final_estimator=LogisticRegression(max_iter=2000),\n",
    "            n_jobs=-1,\n",
    "            cv=5  # StackingClassifier умеет использовать CV для построения мета-признаков\n",
    "        )\n",
    "        model_cv_scores['Stacking'] = float(cross_val_score(stack_cv_cl, X_train, y_train, cv=5, scoring=scoring, n_jobs=-1).mean())\n",
    "    except Exception:\n",
    "        model_cv_scores['Stacking'] = None\n",
    "else:\n",
    "    model_cv_scores['Stacking'] = None\n",
    "\n",
    "print('\\nCV scores on train (used for model selection):')\n",
    "for k, v in model_cv_scores.items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "# Выбираем модель с наилучшим CV-score\n",
    "valid_scores = {k: v for k, v in model_cv_scores.items() if v is not None}\n",
    "if not valid_scores:\n",
    "    raise RuntimeError(\"Не удалось получить CV-оценки для выбора лучшей модели — проверьте доступность gs_* или cross_val_score.\")\n",
    "best_model_name = max(valid_scores, key=valid_scores.get)\n",
    "print(f\"\\nSelected best model by CV on train: {best_model_name}\")\n",
    "\n",
    "# Получаем объект модели для дальнейшей оценки на тесте.\n",
    "# Если это модель из GridSearch — используем её best_estimator_, иначе создаём/обучаем подходящую модель.\n",
    "model_map = {\n",
    "    'LogisticRegression': gs_lr.best_estimator_ if 'gs_lr' in locals() else None,\n",
    "    'DecisionTree': gs_dt.best_estimator_ if 'gs_dt' in locals() else None,\n",
    "    'RandomForest': gs_rf.best_estimator_ if 'gs_rf' in locals() else None,\n",
    "    'GradientBoosting': gs_gb.best_estimator_ if 'gs_gb' in locals() else None,\n",
    "}\n",
    "if best_model_name == 'Dummy':\n",
    "    best_model = dummy\n",
    "    best_model.fit(X_train, y_train)\n",
    "elif best_model_name == 'Stacking':\n",
    "    # берем ранее созданный stack_cv_cl (unfitted) и обучаем на train\n",
    "    stack_cv_cl.fit(X_train, y_train)\n",
    "    best_model = stack_cv_cl\n",
    "else:\n",
    "    best_model = model_map.get(best_model_name)\n",
    "    if best_model is None:\n",
    "        raise RuntimeError(f\"Best model {best_model_name} not available in model_map.\")\n",
    "    # best_model у best_estimator_ для GridSearch уже обучен на X_train\n",
    "    # но можно заново вызвать fit для гарантии\n",
    "    # best_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Final model object used for test evaluation: {best_model}\")\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "try:\n",
    "    y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba_best = None\n",
    "\n",
    "metrics_best = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_best)),\n",
    "    'f1': float(f1_score(y_test, y_pred_best, average='binary' if len(np.unique(y))==2 else 'macro')),\n",
    "}\n",
    "if len(np.unique(y)) == 2 and y_proba_best is not None:\n",
    "    metrics_best['roc_auc'] = float(roc_auc_score(y_test, y_proba_best))\n",
    "else:\n",
    "    metrics_best['roc_auc'] = None\n",
    "\n",
    "# Обновим results и meta для отчёта (только для лучшей модели - тестовые метрики)\n",
    "results[best_model_name] = metrics_best\n",
    "best_meta = {\n",
    "    'best_model_name': best_model_name,\n",
    "    'selection_metric': metric_for_selection,\n",
    "    'cv_score': valid_scores[best_model_name],\n",
    "    'test_metrics': metrics_best,\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "}\n",
    "print('Selected best model test metrics:', metrics_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d0286",
   "metadata": {},
   "source": [
    "## 9. Permutation importance для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbd8f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing permutation importance for best model: Stacking\n",
      "\n",
      "Top features (permutation importance):\n",
      "feature  importance_mean  importance_std\n",
      "    f16         0.084711        0.004335\n",
      "    f01         0.037459        0.003220\n",
      "    f23         0.018526        0.001976\n",
      "    f07         0.014637        0.002024\n",
      "    f30         0.013985        0.002195\n",
      "    f08         0.013889        0.001631\n",
      "    f12         0.013726        0.001882\n",
      "    f19         0.013459        0.001677\n",
      "    f15         0.011993        0.001470\n",
      "    f29         0.011874        0.002427\n",
      "    f18         0.011422        0.001966\n",
      "    f02         0.010156        0.002085\n",
      "    f13         0.009452        0.001814\n",
      "    f05         0.009348        0.002151\n",
      "    f34         0.009119        0.001498\n"
     ]
    }
   ],
   "source": [
    "if best_model is not None:\n",
    "    print('Computing permutation importance for best model:', best_model_name)\n",
    "    try:\n",
    "        r = permutation_importance(best_model, X_test, y_test, n_repeats=30, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        imp_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance_mean': r.importances_mean,\n",
    "            'importance_std': r.importances_std\n",
    "        }).sort_values('importance_mean', ascending=False).reset_index(drop=True)\n",
    "        print('\\nTop features (permutation importance):')\n",
    "        print(imp_df.head(15).to_string(index=False))\n",
    "        imp_df.to_csv(ARTIFACTS_DIR / 'feature_importance.csv', index=False)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.barh(imp_df['feature'].head(15)[::-1], imp_df['importance_mean'].head(15)[::-1])\n",
    "        plt.xlabel('Permutation importance (mean)')\n",
    "        plt.title(f'Permutation importance (best model: {best_model_name})')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / 'permutation_importance.png', dpi=150)\n",
    "        plt.close()\n",
    "    except Exception as exc:\n",
    "        print('Permutation importance failed:', exc)\n",
    "else:\n",
    "    print('No best model available for permutation importance')\n",
    "\n",
    "if 'best_rf' in locals() and best_rf is not None:\n",
    "    try:\n",
    "        fi = best_rf.feature_importances_\n",
    "        fi_df = pd.DataFrame({'feature': X.columns, 'importance': fi}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "        fi_df.to_csv(ARTIFACTS_DIR / 'rf_feature_importance.csv', index=False)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.barh(fi_df['feature'].head(15)[::-1], fi_df['importance'].head(15)[::-1])\n",
    "        plt.xlabel('Feature importance (RF)')\n",
    "        plt.title('Random Forest feature importances (top 15)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / 'rf_feature_importance.png', dpi=150)\n",
    "        plt.close()\n",
    "    except Exception as exc:\n",
    "        print('RF feature importance failed:', exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ae3de",
   "metadata": {},
   "source": [
    "## 10. Сохранение артефактов: метрики, summary поиска, модель, метаданные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e4997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts written to artifacts\n"
     ]
    }
   ],
   "source": [
    "# metrics_test.json\n",
    "with open(ARTIFACTS_DIR / 'metrics_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# search_summaries.json\n",
    "with open(ARTIFACTS_DIR / 'search_summaries.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(search_summaries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# best_model.joblib + metadata\n",
    "if best_model is not None:\n",
    "    joblib.dump(best_model, ARTIFACTS_DIR / 'best_model.joblib')\n",
    "    best_meta = {\n",
    "        'best_model_name': best_model_name,\n",
    "        'selection_metric': metric_for_selection,\n",
    "        'test_metrics': results.get(best_model_name, {}),\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    }\n",
    "    with open(ARTIFACTS_DIR / 'best_model_meta.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(best_meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('Artifacts written to', ARTIFACTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5c629",
   "metadata": {},
   "source": [
    "## 11. ROC / PR и confusion matrix сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897ff0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figures saved to artifacts\\figures\n"
     ]
    }
   ],
   "source": [
    "if len(np.unique(y)) == 2:\n",
    "    # plot ROC for best and for others\n",
    "    plt.figure(figsize=(6,6))\n",
    "    for name, model in [('LogReg', best_lr), ('DT', best_dt), ('RF', best_rf), ('GB', best_gb)]:\n",
    "        try:\n",
    "            proba = model.predict_proba(X_test)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Include stacking curve if available\n",
    "    if 'stack' in locals():\n",
    "        try:\n",
    "            proba = stack.predict_proba(X_test)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"Stacking (AUC={roc_auc:.3f})\", linewidth=2, linestyle='--')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    plt.plot([0,1],[0,1], linestyle=':', color='grey')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / 'roc_curves_all.png', dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # PR curve for best model\n",
    "    try:\n",
    "        proba_best = (best_model.predict_proba(X_test)[:,1]) if best_model is not None else None\n",
    "        if proba_best is not None:\n",
    "            precision, recall, _ = precision_recall_curve(y_test, proba_best)\n",
    "            ap = average_precision_score(y_test, proba_best)\n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.plot(recall, precision, label=f'Best (AP={ap:.3f})')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title('Precision-Recall curve')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(FIG_DIR / 'pr_curve_best.png', dpi=150)\n",
    "            plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # confusion matrix for best model\n",
    "    try:\n",
    "        if best_model is not None:\n",
    "            y_pred_best = best_model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred_best)\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "            plt.title('Confusion matrix (best)')\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(np.unique(y)))\n",
    "            plt.xticks(tick_marks, tick_marks)\n",
    "            plt.yticks(tick_marks, tick_marks)\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    plt.text(j, i, cm[i,j], ha='center', va='center', color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(FIG_DIR / 'confusion_matrix_best.png', dpi=150)\n",
    "            plt.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print('Figures saved to', FIG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63bf785",
   "metadata": {},
   "source": [
    "## 12. Генерация краткого отчёта report.md (в HW06/report.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8dd800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating report.md ...\n",
      "Wrote report to report.md\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating report.md ...\")\n",
    "report_lines = []\n",
    "report_lines.append(\"# HW06 – Report\\n\")\n",
    "# 1. Dataset\n",
    "report_lines.append(\"## 1. Dataset\\n\")\n",
    "report_lines.append(f\"- Какой датасет выбран: `S06-hw-dataset-02.csv`\\n\")\n",
    "report_lines.append(f\"- Размер: {df.shape[0]} строк, {X.shape[1]} признаков\\n\")\n",
    "report_lines.append(\"- Целевая переменная: `target`\\n\")\n",
    "for val, cnt in df[\"target\"].value_counts().items():\n",
    "    pct = df[\"target\"].value_counts(normalize=True)[val]\n",
    "    report_lines.append(f\"  - класс {val}: {cnt} ({pct:.2%})\\n\")\n",
    "report_lines.append(\"- Признаки: все числовые (при необходимости некоторые были приведены к числовому типу).\\n\\n\")\n",
    "\n",
    "# 2. Protocol\n",
    "report_lines.append(\"## 2. Protocol\\n\")\n",
    "report_lines.append(f\"- Разбиение: train/test = {1-TEST_SIZE:.2f}/{TEST_SIZE:.2f}, random_state={RANDOM_STATE}\\n\")\n",
    "report_lines.append(\"- Подбор: GridSearchCV на train (см. search_summaries.json); CV-оценки использованы для выбора модели, тест использован один раз для финальной оценки.\\n\")\n",
    "report_lines.append(f\"- Метрики: accuracy, F1, ROC-AUC (для бинарных). Для CV использовался scoring='{scoring}'.\\n\\n\")\n",
    "\n",
    "# 3. Models\n",
    "report_lines.append(\"## 3. Models\\n\")\n",
    "report_lines.append(\"- DummyClassifier (most_frequent) — baseline\\n\")\n",
    "report_lines.append(\"- LogisticRegression (Pipeline: StandardScaler + LogisticRegression), C подобран через GridSearchCV\\n\")\n",
    "report_lines.append(\"- DecisionTreeClassifier — подбор max_depth + min_samples_leaf через GridSearchCV\\n\")\n",
    "report_lines.append(\"- RandomForestClassifier — подбор max_depth/max_features/min_samples_leaf через GridSearchCV\\n\")\n",
    "report_lines.append(\"- GradientBoostingClassifier — подбор learning_rate/max_depth через GridSearchCV\\n\")\n",
    "report_lines.append(\"- StackingClassifier (опционально) — обучён на train, оценён на test\\n\\n\")\n",
    "\n",
    "# 4. Results\n",
    "report_lines.append(\"## 4. Results\\n\")\n",
    "report_lines.append(\"Таблица финальных метрик на test:\\n\\n\")\n",
    "# add markdown table\n",
    "try:\n",
    "    md_table = results_df.to_markdown()\n",
    "    report_lines.append(md_table + \"\\n\\n\")\n",
    "except Exception:\n",
    "    report_lines.append(str(results_df) + \"\\n\\n\")\n",
    "\n",
    "report_lines.append(f\"- Победитель (по CV, затем по тестовой метрике): **{best_model_name}** \\n\\n\")\n",
    "\n",
    "# 5. Analysis\n",
    "report_lines.append(\"## 5. Analysis\\n\")\n",
    "report_lines.append(\"- Устойчивость: при желании запустите несколько прогонов с разными random_state (опционально, не включено в код по умолчанию).\\n\")\n",
    "report_lines.append(\"- Ошибки: confusion matrix сохранена в artifacts/figures/confusion_matrix_best.png (если best_model поддерживает predict).\\n\")\n",
    "report_lines.append(\"- Интерпретация: permutation importance сохранён в artifacts/feature_importance.csv и artifacts/figures/permutation_importance.png (если был успешно рассчитан).\\n\\n\")\n",
    "\n",
    "# 6. Conclusion\n",
    "report_lines.append(\"## 6. Conclusion\\n\")\n",
    "report_lines.append(\"- Ансамбли (RF/GB/Stacking) обычно дают лучший баланс bias/variance по сравнению с одиночными деревьями или линейными моделями на этих данных.\\n\")\n",
    "report_lines.append(\"- Для честного эксперимента подбор гиперпараметров выполняйте только на train, используйте CV, и тест применяйте один раз для финальной оценки.\\n\")\n",
    "report_lines.append(\"- Сохраняйте модели и метаданные (best_model.joblib, best_model_meta.json) для воспроизводимости.\\n\")\n",
    "report_lines.append(\"- Для дисбалансных задач дополнительно смотрите PR-кривую и average_precision_score.\\n\")\n",
    "\n",
    "report_path = HW_DIR / \"report.md\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(report_lines)\n",
    "print(\"Wrote report to\", report_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
